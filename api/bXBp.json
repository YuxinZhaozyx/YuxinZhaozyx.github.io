{"title":"MPI基础","date":"2020-05-17T14:09:54.000Z","thumbnail":"mpi/mpi_logo.jpg","link":"mpi","comments":true,"tags":["mpi","multiprocessing"],"categories":["tools"],"updated":"2022-01-04T08:35:48.603Z","content":"<p>MPI(Message Passing Interface)是消息传递函数库的标准规范，有着多种实现，如MPICH、OPEN-MPI等。本文以MPICH为例介绍MPI的基本使用。</p>\n<a id=\"more\"></a>\n\n<h1 id=\"安装\">安装<a href=\"mpi#安装\"></a></h1><figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install mpich libmpich-dev</span><br></pre></td></tr></table></div></figure>\n\n<h1 id=\"第一个MPI程序\">第一个MPI程序<a href=\"mpi#第一个MPI程序\"></a></h1><figure class=\"highlight\"><figcaption><span>helloworld.c</span></figcaption><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"mpi.h\"</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> *argv[])</span> </span>&#123;</span><br><span class=\"line\">    MPI_Init(&amp;argc, &amp;argv); <span class=\"comment\">/* MPI的初始化函数 */</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"Hello, world!\\n\"</span>);</span><br><span class=\"line\">    MPI_Finalize(); <span class=\"comment\">/* MPI的结束函数 */</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></div></figure>\n\n<ul>\n<li><code>MPI_Init()</code> 和 <code>MPI_Finalize()</code> 将被并行化。</li>\n</ul>\n<p><strong>编译：</strong></p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mpicc helloworld.c -o helloworld</span><br></pre></td></tr></table></div></figure>\n\n<p><strong>运行：</strong></p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mpirun -n 4 ./helloworld</span><br></pre></td></tr></table></div></figure>\n\n<ul>\n<li>其中<code>-n 4</code> 指定进程数为4。</li>\n</ul>\n<p><strong>输出：</strong></p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Hello, world!</span><br><span class=\"line\">Hello, world!</span><br><span class=\"line\">Hello, world!</span><br><span class=\"line\">Hello, world!</span><br></pre></td></tr></table></div></figure>\n\n<h1 id=\"我是谁？世界有多大？\">我是谁？世界有多大？<a href=\"mpi#我是谁？世界有多大？\"></a></h1><p>在写MPI程序时，我们常需要知道</p>\n<ul>\n<li>任务由多少个进程进行并行计算?</li>\n<li>我是哪一个进程？</li>\n</ul>\n<p>MPI提供了两个函数分别用于解决以上两个问题：</p>\n<ul>\n<li><code>int MPI_Comm_size(MPI_Comm comm, int *size)</code><ul>\n<li>获取指定通信域的进程数</li>\n</ul>\n</li>\n<li><code>int MPI_Comm_rank(MPI_Comm comm, int*rank)</code><ul>\n<li>获取指定进程的编号</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"mpi.h\"</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> *argv[])</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> id, numProcs;</span><br><span class=\"line\">    MPI_Init(&amp;argc, &amp;argv); <span class=\"comment\">/* MPI的初始化函数 */</span></span><br><span class=\"line\">    MPI_Comm_size(MPI_COMM_WORLD, &amp;numProcs); <span class=\"comment\">/* 获取进程数 */</span></span><br><span class=\"line\">    MPI_Comm_rank(MPI_COMM_WORLD, &amp;id); <span class=\"comment\">/* 获取进程号 */</span></span><br><span class=\"line\">    <span class=\"built_in\">printf</span>(<span class=\"string\">\"Hello, I am %d of %d!\\n\"</span>, id, numProcs);</span><br><span class=\"line\">    MPI_Finalize(); <span class=\"comment\">/* MPI的结束函数 */</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></div></figure>\n\n<p><strong>输出：</strong></p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Hello, I am 0 of 4!</span><br><span class=\"line\">Hello, I am 1 of 4!</span><br><span class=\"line\">Hello, I am 2 of 4!</span><br><span class=\"line\">Hello, I am 3 of 4!</span><br></pre></td></tr></table></div></figure>\n\n<h1 id=\"MPI数据类型\">MPI数据类型<a href=\"mpi#MPI数据类型\"></a></h1><p>MPI的数据类型分为两种：<strong>预定义类型</strong>和<strong>派生数据类型</strong>。</p>\n<ul>\n<li>MPI通过预定义数据类型来解决异构计算中的互操作性问题</li>\n<li>MPI派生数据类型用于定义由于数据类型不同且地址空间不连续的数据项组成的消息。</li>\n</ul>\n<h2 id=\"MPI预定义数据类型\">MPI预定义数据类型<a href=\"mpi#MPI预定义数据类型\"></a></h2><div class=\"article-bounded\"><div class=\"article-table\"><table>\n<thead>\n<tr>\n<th>MPI(C语言绑定)</th>\n<th>C</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>MPI_BYTE</code></td>\n<td></td>\n</tr>\n<tr>\n<td><code>MPI_CHAR</code></td>\n<td><code>signed char</code></td>\n</tr>\n<tr>\n<td><code>MPI_DOUBLE</code></td>\n<td><code>double</code></td>\n</tr>\n<tr>\n<td><code>MPI_FLOAT</code></td>\n<td><code>float</code></td>\n</tr>\n<tr>\n<td><code>MPI_INT</code></td>\n<td><code>int</code></td>\n</tr>\n<tr>\n<td><code>MPI_LONG</code></td>\n<td><code>long</code></td>\n</tr>\n<tr>\n<td><code>MPI_LONG_DOUBLE</code></td>\n<td><code>long double</code></td>\n</tr>\n<tr>\n<td><code>MPI_PACKED</code></td>\n<td></td>\n</tr>\n<tr>\n<td><code>MPI_SHORT</code></td>\n<td><code>short</code></td>\n</tr>\n<tr>\n<td><code>MPI_UNSIGNED_CHAR</code></td>\n<td><code>unsigned char</code></td>\n</tr>\n<tr>\n<td><code>MPI_UNSIGNED</code></td>\n<td><code>unsigned int</code></td>\n</tr>\n<tr>\n<td><code>MPI_UNSIGNED_LONG</code></td>\n<td><code>unsigned long</code></td>\n</tr>\n<tr>\n<td><code>MPI_UNSIGNED_SHORT</code></td>\n<td><code>unsigned short</code></td>\n</tr>\n</tbody></table></div></div>\n<ul>\n<li><code>MPI_BYTE</code> 表示一个字节</li>\n<li><code>MPI_PACKED</code> 预定义数据类型被用来实现传输地址空间不连续的数据项</li>\n</ul>\n<h2 id=\"MPI常用常量\">MPI常用常量<a href=\"mpi#MPI常用常量\"></a></h2><div class=\"article-bounded\"><div class=\"article-table\"><table>\n<thead>\n<tr>\n<th>常量名</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>MPI_MAX_PROCESSOR_NAME</code></td>\n<td><code>MPI_Get_processor_name</code>返回的处理器名称最大长度</td>\n</tr>\n<tr>\n<td><code>MPI_PROC_NULL</code></td>\n<td>空进程，与空进程进行通信相当于空操作</td>\n</tr>\n<tr>\n<td><code>MPI_COMM_WORLD</code></td>\n<td>缺省通信域</td>\n</tr>\n<tr>\n<td><code>MPI_COMM_NULL</code></td>\n<td>空通信域</td>\n</tr>\n<tr>\n<td><code>MPI_UNDEFINED_RANK</code></td>\n<td>未定义的进程号</td>\n</tr>\n<tr>\n<td><code>MPI_ANY_SOURCE</code></td>\n<td>接收操作中用于表示从任何源地址接受</td>\n</tr>\n<tr>\n<td><code>MPI_ANY_TAG</code></td>\n<td>接收操作中用于表示接收任何标签的消息</td>\n</tr>\n</tbody></table></div></div>\n<h1 id=\"消息传递\">消息传递<a href=\"mpi#消息传递\"></a></h1><h2 id=\"MPI-Send\"><code>MPI_Send</code><a href=\"mpi#MPI-Send\"></a></h2><figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Send</span><span class=\"params\">(<span class=\"keyword\">void</span> *buf, <span class=\"keyword\">int</span> count, MPI_Datatype datatype, <span class=\"keyword\">int</span> dest, <span class=\"keyword\">int</span> tag, MPI_Comm comm)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<ul>\n<li><code>buf</code>：所发送消息的首地址</li>\n<li><code>count</code>: 将发送的数据的个数</li>\n<li><code>datatype</code>: 发送数据的MPI数据类型</li>\n<li><code>dest</code>: 接收消息的进程的标识号，取值范围为0～进程数-1 或 <code>MPI_PROC_NULL</code></li>\n<li><code>tag</code>: 消息标签，取值为0～<code>MPI_TAG_UB</code></li>\n<li><code>comm</code>: 通信域</li>\n</ul>\n<h2 id=\"MPI-Recv\"><code>MPI_Recv</code><a href=\"mpi#MPI-Recv\"></a></h2><figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Recv</span><span class=\"params\">(<span class=\"keyword\">void</span> *buf, <span class=\"keyword\">int</span> count, MPI_Datatype datatype, <span class=\"keyword\">int</span> source, <span class=\"keyword\">int</span> tag, MPI_Comm comm, MPI_Status *status)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<ul>\n<li><code>buf</code>: 接收消息数据的首地址</li>\n<li><code>count</code>: 接收数据的最大个数</li>\n<li><code>datatype</code>: 接收数据的MPI数据类型</li>\n<li><code>source</code>: 发送消息的进程的标识号</li>\n<li><code>tag</code>: 消息标签，取值为0～<code>MPI_TAG_UB</code></li>\n<li><code>comm</code>: 通信域</li>\n<li><code>status</code>: 返回状态</li>\n</ul>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;stdio.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">&lt;string.h&gt;</span></span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"mpi.h\"</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">const</span> <span class=\"keyword\">int</span> MAX_STRING = <span class=\"number\">100</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">(<span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span> *argv[])</span> </span>&#123;</span><br><span class=\"line\">    <span class=\"keyword\">char</span> greeting[MAX_STRING];</span><br><span class=\"line\">    <span class=\"keyword\">int</span>  comm_size;</span><br><span class=\"line\">    <span class=\"keyword\">int</span>  my_rank;</span><br><span class=\"line\"></span><br><span class=\"line\">    MPI_Init(&amp;argc, &amp;argv);</span><br><span class=\"line\">    MPI_Comm_size(MPI_COMM_WORLD, &amp;comm_size);</span><br><span class=\"line\">    MPI_Comm_rank(MPI_COMM_WORLD, &amp;my_rank);</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (my_rank != <span class=\"number\">0</span>) &#123;</span><br><span class=\"line\">        <span class=\"built_in\">sprintf</span>(greeting, <span class=\"string\">\"Hello, world! I am process %d of %d!\"</span>, my_rank, comm_size);</span><br><span class=\"line\">        MPI_Send(greeting, <span class=\"built_in\">strlen</span>(greeting) + <span class=\"number\">1</span>, MPI_CHAR, <span class=\"number\">0</span>, <span class=\"number\">0</span>, MPI_COMM_WORLD);</span><br><span class=\"line\">    &#125; <span class=\"keyword\">else</span> &#123;</span><br><span class=\"line\">        <span class=\"built_in\">printf</span>(<span class=\"string\">\"Greetings from process %d of %d!\\n\"</span>, my_rank, comm_size);</span><br><span class=\"line\">        <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> q = <span class=\"number\">1</span>; q &lt; comm_size; q++) &#123;</span><br><span class=\"line\">            MPI_Recv(greeting, MAX_STRING, MPI_CHAR, q, <span class=\"number\">0</span>, MPI_COMM_WORLD, MPI_STATUS_IGNORE);</span><br><span class=\"line\">            <span class=\"built_in\">printf</span>(<span class=\"string\">\"%s\\n\"</span>, greeting);</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    MPI_Finalize();</span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></div></figure>\n\n<p>输出：</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Greetings from process 0 of 4!</span><br><span class=\"line\">Hello, world! I am process 1 of 4!</span><br><span class=\"line\">Hello, world! I am process 2 of 4!</span><br><span class=\"line\">Hello, world! I am process 3 of 4!</span><br></pre></td></tr></table></div></figure>\n\n<h1 id=\"通信域\">通信域<a href=\"mpi#通信域\"></a></h1><p>MPI提供了丰富的函数用于管理通信域</p>\n<div class=\"article-bounded\"><div class=\"article-table\"><table>\n<thead>\n<tr>\n<th>函数名</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>MPI_Comm_size</code></td>\n<td>获取指定通信域中进程的个数</td>\n</tr>\n<tr>\n<td><code>MPI_Comm_rank</code></td>\n<td>获取当前进程在指定通信域中的编号</td>\n</tr>\n<tr>\n<td><code>MPI_Comm_compare</code></td>\n<td>对给定的两个通信域进行比较</td>\n</tr>\n<tr>\n<td><code>MPI_Comm_dup</code></td>\n<td>复制一个已有的通信域生成一个新的通信域，两者除了通信上下文不同，其他都一样</td>\n</tr>\n<tr>\n<td><code>MPI_Comm_create</code></td>\n<td>根据给定的进程组创建一个新的通信域</td>\n</tr>\n<tr>\n<td><code>MPI_Comm_split</code></td>\n<td>从一个指定通信域分裂出多个子通信域，每个子通信域中的进程都是原通信域中的进程</td>\n</tr>\n<tr>\n<td><code>MPI_Comm_free</code></td>\n<td>释放一个通信域</td>\n</tr>\n</tbody></table></div></div>\n<h1 id=\"消息状态\">消息状态<a href=\"mpi#消息状态\"></a></h1><p><code>MPI_Recv</code>中的<code>status</code>存放接收消息的状态</p>\n<ul>\n<li><code>MPI_Status</code> 是MPI定义的一个数据类型，使用之前需要用户为其分配空间</li>\n<li>包含：<ul>\n<li><code>status.MPI_SOURCE</code>：发送数据进程的标识</li>\n<li><code>status.MPI_TAG</code>：发送数据使用的tag</li>\n<li><code>status.MPI_ERROR</code>：本接收操作返回的错误代码</li>\n</ul>\n</li>\n</ul>\n<p>还可以通过<code>status</code>获取实际接收到的消息的长度</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Get_count</span><span class=\"params\">(MPI_Status status, MPI_Datatype datatype, <span class=\"keyword\">int</span> *count)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<ul>\n<li><code>status</code>: 接收操作的返回值</li>\n<li><code>datatype</code>: 接收缓冲区中元素的数据类型</li>\n<li><code>count</code>: 接收消息中的元素个数</li>\n</ul>\n<h1 id=\"点对点通信\">点对点通信<a href=\"mpi#点对点通信\"></a></h1><h2 id=\"通信模式\">通信模式<a href=\"mpi#通信模式\"></a></h2><p>MPI提供了以下四种通信模式</p>\n<ul>\n<li>标准(standard)模式<ul>\n<li>发送的结束等于消息已从发送方发出，而不是滞留在发送方的系统缓冲区中</li>\n<li>对应 <code>MPI_Send</code></li>\n</ul>\n</li>\n<li>缓冲(buffered)模式<ul>\n<li>用户需要事先申请一块缓冲区，通过<code>MPI_Buffer_attch</code>将缓冲区绑定一个进程后，发送过程中写入此缓冲区，不依赖于接收方的接收操作。</li>\n<li>发送结束仅表示消息进入用户指定的缓冲区中。</li>\n<li>对应 <code>MPI_Bsend</code></li>\n<li>用 <code>MPI_Buffer_detach</code> 可以回收申请的缓冲区。</li>\n</ul>\n</li>\n<li>同步(synchronous)模式<ul>\n<li>双方握手后才进行消息的发送，不需要附加的缓冲区</li>\n<li>对应 <code>MPI_Ssend</code></li>\n</ul>\n</li>\n<li>就绪(ready)模式<ul>\n<li>接收方必须先做出接收操作，处于就绪状态，发送方才能成功发送消息。</li>\n<li>对应 <code>MPI_Rsend</code></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"通信机制\">通信机制<a href=\"mpi#通信机制\"></a></h2><h3 id=\"阻塞通信\">阻塞通信<a href=\"mpi#阻塞通信\"></a></h3><p><code>MPI_Send</code>和<code>MPI_Recv</code>都是阻塞型的</p>\n<p>阻塞通信返回的条件：</p>\n<ul>\n<li>通信操作已完成</li>\n<li>调用的缓冲区可用</li>\n</ul>\n<h3 id=\"非阻塞通信\">非阻塞通信<a href=\"mpi#非阻塞通信\"></a></h3><p><code>MPI_Send</code>和<code>MPI_Recv</code>都有对应的非阻塞版本：<code>MPI_Isend</code>和<code>MPI_Irecv</code>。</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Isend</span><span class=\"params\">(<span class=\"keyword\">void</span> *buf, <span class=\"keyword\">int</span> count, MPI_Datatype datatype, <span class=\"keyword\">int</span> dest, <span class=\"keyword\">int</span> tag, MPI_Comm comm, MPI_Request *request)</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Irecv</span><span class=\"params\">(<span class=\"keyword\">void</span> *buf, <span class=\"keyword\">int</span> count, MPI_Datatype datatype, <span class=\"keyword\">int</span> source, <span class=\"keyword\">int</span> tag, MPI_Comm comm, MPI_Request *request)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<ul>\n<li>与其阻塞版本比较多了一个参数 <code>request</code>: 非阻塞通信完成对象(句柄)</li>\n</ul>\n<p>其他通信模式也有其非阻塞版本: <code>MPI_Ibsend</code>, <code>MPI_Issend</code>, <code>MPI_Irsend</code>。</p>\n<h4 id=\"通信检测\">通信检测<a href=\"mpi#通信检测\"></a></h4><figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Wait</span><span class=\"params\">(MPI_Request *request, MPI_Status *status)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<ul>\n<li>等待指定通信请求完成才返回</li>\n<li>成功返回时，<code>status</code>包含关于完成的通信的消息，相应的<code>request</code>被置为<code>MPI_REQUEST_NULL</code>。</li>\n</ul>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Test</span><span class=\"params\">(MPI_Request *request, <span class=\"keyword\">int</span> *flag, MPI_Status *status)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<ul>\n<li>无论通信是否完成都立刻返回，<code>flag</code> 为1表示通信完成。</li>\n</ul>\n<p><strong>其他通信检测函数：</strong></p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Waitany</span><span class=\"params\">(<span class=\"keyword\">int</span> count, MPI_Request *array_of_requests, <span class=\"keyword\">int</span> *index, MPI_Status *status)</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Waitall</span><span class=\"params\">(<span class=\"keyword\">int</span> count, MPI_Request *array_of_requests, <span class=\"keyword\">int</span> *index, MPI_Status *array_of_statuses)</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Waitsome</span><span class=\"params\">(<span class=\"keyword\">int</span> incount, MPI_Request *array_of_requests, <span class=\"keyword\">int</span> *outcount, <span class=\"keyword\">int</span> *array_of_indices, MPI_Status *array_of_statuses)</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Testany</span><span class=\"params\">(<span class=\"keyword\">int</span> count, MPI_Request *array_of_requests, <span class=\"keyword\">int</span> *index, <span class=\"keyword\">int</span> *flag, MPI_Status *status)</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Testall</span><span class=\"params\">(<span class=\"keyword\">int</span> count, MPI_Request *array_of_requests, <span class=\"keyword\">int</span> *index, <span class=\"keyword\">int</span> *flag, MPI_Status *array_of_statuses)</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Testsome</span><span class=\"params\">(<span class=\"keyword\">int</span> incount, MPI_Request *array_of_requests, <span class=\"keyword\">int</span> *outcount, <span class=\"keyword\">int</span> *array_of_indices, MPI_Status *array_of_statuses)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<h4 id=\"请求释放\">请求释放<a href=\"mpi#请求释放\"></a></h4><figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Request_free</span><span class=\"params\">(MPI_Request request)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<ul>\n<li>释放指定的通信请求及其所占用的内存资源</li>\n<li>若该通信尚未完成，则等待通信完成后，不会影响该通信</li>\n<li>成功返回后<code>request</code>被重置为<code>MPI_REQUEST_NULL</code></li>\n</ul>\n<h4 id=\"请求撤销\">请求撤销<a href=\"mpi#请求撤销\"></a></h4><figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Cancel</span><span class=\"params\">(MPI_Request request)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<ul>\n<li>非阻塞型，用于取消一个尚未完成的通信，但不能保证一定会取消，如果通信已经开始，则无法取消。</li>\n<li>调用<code>MPI_Cancel</code>后仍需要<code>MPI_Wait</code>, <code>MPI_Test</code>, <code>MPI_Request_free</code>来释放该通信请求。</li>\n</ul>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Test_cancelled</span><span class=\"params\">(MPI_Status status, <span class=\"keyword\">int</span> *flag)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<ul>\n<li>检测是否取消成功</li>\n</ul>\n<h2 id=\"消息探测\">消息探测<a href=\"mpi#消息探测\"></a></h2><p><code>MPI_Probe</code>和<code>MPI_Iprobe</code>函数探测接收消息的内容。用户根据探测到的消息内容决定如何接收这些消息，如根据消息大小分配缓冲区等。前者为阻塞版本，后者为非阻塞版本。</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Probe</span><span class=\"params\">(<span class=\"keyword\">int</span> source, <span class=\"keyword\">int</span> tag, MPI_Comm comm, MPI_Status *status)</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Iprobe</span><span class=\"params\">(<span class=\"keyword\">int</span> source, <span class=\"keyword\">int</span> tag, MPI_Comm comm, <span class=\"keyword\">int</span> *flag, MPI_Status *status)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<ul>\n<li><code>source</code>: 数据源的rank，可以是 <code>MPI_ANY_SOURCE</code></li>\n<li><code>tag</code>: 数据标签，可以是 <code>MPI_ANY_TAG</code></li>\n<li><code>comm</code>: 通信域</li>\n<li><code>flag</code>: 布尔值，探测到与否</li>\n<li><code>status</code>: 探测到的消息的内容</li>\n</ul>\n<h2 id=\"MPI-Sendrecv\"><code>MPI_Sendrecv</code><a href=\"mpi#MPI-Sendrecv\"></a></h2><figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Sendrecv</span><span class=\"params\">(<span class=\"keyword\">void</span> *sendbuf, <span class=\"keyword\">int</span> sendcount, MPI_Datatype sendtype, <span class=\"keyword\">int</span> dest, <span class=\"keyword\">int</span> sendtag,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                 <span class=\"keyword\">void</span> *recvbuf, <span class=\"keyword\">int</span> recvcount, MPI_Datatype recvtype, <span class=\"keyword\">int</span> source, <span class=\"keyword\">int</span> recvtag, MPI_Comm comm, MPI_Status *status)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<ul>\n<li>通过轮转的方式实现一个语句同时向其他进程发送数据和从其他进程接收数据的操作</li>\n<li>系统会优化通信次序，从而有效避免不合理的通信次序，最大程度避免死锁</li>\n</ul>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> a, b;</span><br><span class=\"line\"><span class=\"comment\">// ...</span></span><br><span class=\"line\">MPI_Status status;</span><br><span class=\"line\"><span class=\"keyword\">int</span> dest = (rank + <span class=\"number\">1</span>) % p;  <span class=\"comment\">// p 为进程个数</span></span><br><span class=\"line\"><span class=\"keyword\">int</span> source = (rank + p - <span class=\"number\">1</span>) % p;</span><br><span class=\"line\">MPI_Sendrecv(&amp;a, <span class=\"number\">1</span>, MPI_INT, dest, <span class=\"number\">99</span>, &amp;b, <span class=\"number\">1</span>, MPI_INT, source, <span class=\"number\">99</span>, MPI_COMM_WORLD, &amp;status);</span><br></pre></td></tr></table></div></figure>\n\n<h2 id=\"点对点通信应用示例\">点对点通信应用示例<a href=\"mpi#点对点通信应用示例\"></a></h2><p><strong>任务：</strong>计算 Z=R(Q(P(W)))​。</p>\n<h3 id=\"流水线型\">流水线型<a href=\"mpi#流水线型\"></a></h3><p><img src=\"mpi/mpi-pipeline.svg\" alt class=\"article-img\"></p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">while</span> (Not_Done) &#123;</span><br><span class=\"line\">    MPI_Irecv(NextX, ... );</span><br><span class=\"line\">    MPI_Isend(PreviousY, ... );</span><br><span class=\"line\">    CurrentY = Q(CurrentX);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></div></figure>\n\n<h3 id=\"双缓冲流水线型\">双缓冲流水线型<a href=\"mpi#双缓冲流水线型\"></a></h3><p><img src=\"mpi/mpi.svg\" alt class=\"article-img\"></p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">while</span> (Not_Done) &#123;</span><br><span class=\"line\">    <span class=\"keyword\">if</span> (X == Xbuf0) &#123;X=Xbuf1; Y=Ybuf1; Xin=Xbuf0; Yout=Ybuf0;&#125;</span><br><span class=\"line\">    <span class=\"keyword\">else</span> &#123;X=Xbuf0; Y=Ybuf0; Y=Ybuf0; Xin=Xbuf1; Yout=Ybuf1;&#125;</span><br><span class=\"line\">    MPI_Irecv(Xin, ..., recv_handle);</span><br><span class=\"line\">    MPI_Isend(Yout, ..., send_handle);</span><br><span class=\"line\">    Y = Q(X); <span class=\"comment\">// 重叠计算</span></span><br><span class=\"line\">    MPI_Wait(recv_handle, recv_status);</span><br><span class=\"line\">    MPI_Wait(send_handle, send_status);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></div></figure>\n\n<h1 id=\"聚合通信\">聚合通信<a href=\"mpi#聚合通信\"></a></h1><p>特点：</p>\n<ul>\n<li>通信空间中所有进程都参与通信操作</li>\n<li>每个进程都需要调用该操作函数</li>\n</ul>\n<p>功能：</p>\n<ul>\n<li><strong>通信</strong>：完成组内数据的传输</li>\n<li><strong>聚集</strong>：在通信的基础上对给定的数据完成一定的操作</li>\n<li><strong>同步</strong>：实现组内所有进程在执行进度上取得一致</li>\n</ul>\n<p>按通信方向分为：</p>\n<ul>\n<li><strong>一对多通信</strong>：一个进程向其他所有的进程发送消息，这个负责发送消息的进程称为Root进程</li>\n<li><strong>多对一通信</strong>：一个进程负责从其他所有的进程接收消息，这个负责接收消息的进程也称为Root进程</li>\n<li><strong>多对多通信</strong>：每个进程都向其他所有的进程发送或接收消息</li>\n</ul>\n<div class=\"article-bounded\"><div class=\"article-table\"><table>\n    <tr>\n        <th>类型</th>\n        <th>函数名</th>\n        <th>含义</th>\n    </tr>\n    <tr>\n        <td rowspan=\"9\">通信</td>\n        <td>MPI_Bcast</td>\n        <td>一对多广播同样的消息</td>\n    </tr>\n    <tr>\n        <td>MPI_Gather</td>\n        <td>多对一收集各个进程的消息</td>\n    </tr>\n    <tr>\n        <td>MPI_Gatherv</td>\n        <td>MPI_Gather的一般化</td>\n    </tr>\n    <tr>\n        <td>MPI_Allgather</td>\n        <td>全局收集</td>\n    </tr>\n    <tr>\n        <td>MPI_Allgatherv</td>\n        <td>MPI_Allgather的一般化</td>\n    </tr>\n    <tr>\n        <td>MPI_Scatter</td>\n        <td>一对多散播不同的消息</td>\n    </tr>\n    <tr>\n        <td>MPI_Scatterv</td>\n        <td>MPI_Scatter的一般化</td>\n    </tr>\n    <tr>\n        <td>MPI_Alltoall</td>\n        <td>多对多全局交换消息</td>\n    </tr>\n    <tr>\n        <td>MPI_Alltoallv</td>\n        <td>MPI_Alltoall的一般化</td>\n    </tr>\n    <tr>\n        <td rowspan=\"4\">聚集</td>\n        <td>MPI_Reduce</td>\n        <td>多对一归约</td>\n    </tr>\n    <tr>\n        <td>MPI_Allreduce</td>\n        <td>MPI_Reduce的一般化</td>\n    </tr>\n    <tr>\n        <td>MPI_Reduce_scatter</td>\n        <td>MPI_Reduce的一般化</td>\n    </tr>\n    <str>\n        <td>MPI_Scan</td>\n        <td>前缀和</td>\n    </str>\n    <tr>\n        <td>同步</td>\n        <td>MPI_Barrier</td>\n        <td>路障同步</td>\n    </tr>\n</table></div></div>\n\n<h2 id=\"MPI-Bcast\"><code>MPI_Bcast</code><a href=\"mpi#MPI-Bcast\"></a></h2><p>广播，一对多</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Bcast</span><span class=\"params\">(<span class=\"keyword\">void</span> *buffer, <span class=\"keyword\">int</span> count, MPI_Datatype datatype, <span class=\"keyword\">int</span> root, MPI_Comm comm)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<ul>\n<li><code>buffer</code>: 发送/接收缓冲区</li>\n<li><code>count</code>: 元素个数</li>\n<li><code>datatype</code>: MPI数据类型</li>\n<li><code>root</code>: root进程号</li>\n<li><code>comm</code>: 通信域</li>\n</ul>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> p, myrank;</span><br><span class=\"line\"><span class=\"keyword\">float</span> buf;</span><br><span class=\"line\">MPI_Comm comm;</span><br><span class=\"line\">MPI_Init(&amp;argc, &amp;argv);</span><br><span class=\"line\">MPI_Comm_rank(comm, &amp;my_rank);</span><br><span class=\"line\">MPI_Comm_size(comm, &amp;p);</span><br><span class=\"line\"><span class=\"keyword\">if</span> (myrank == <span class=\"number\">0</span>) buf = <span class=\"number\">1.0</span>;</span><br><span class=\"line\">MPI_Bcast(&amp;buf, <span class=\"number\">1</span>, MPI_FLOAT, <span class=\"number\">0</span>, comm);</span><br><span class=\"line\">MPI_Finalize()</span><br></pre></td></tr></table></div></figure>\n\n<h2 id=\"MPI-Gather\"><code>MPI_Gather</code><a href=\"mpi#MPI-Gather\"></a></h2><p>多对一，数据收集</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Gather</span><span class=\"params\">(<span class=\"keyword\">void</span> *sendbuf, <span class=\"keyword\">int</span> sendcnt, MPI_Datatype sendtype,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">               <span class=\"keyword\">void</span> *recvbuf, <span class=\"keyword\">int</span> recvcount, MPI_Datatype recvtype, <span class=\"keyword\">int</span> root, MPI_Comm comm)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> p, myrank;</span><br><span class=\"line\"><span class=\"keyword\">float</span> data[<span class=\"number\">10</span>];</span><br><span class=\"line\"><span class=\"keyword\">float</span> *buf;</span><br><span class=\"line\">MPI_Comm comm;</span><br><span class=\"line\">MPI_Init(&amp;argc, &amp;argv);</span><br><span class=\"line\">MPI_Comm_rank(comm, &amp;myrank);</span><br><span class=\"line\">MPI_Comm_size(comm, &amp;p);</span><br><span class=\"line\"><span class=\"keyword\">if</span> (myrank == <span class=\"number\">0</span>)</span><br><span class=\"line\">    buf = (<span class=\"keyword\">float</span>*)<span class=\"built_in\">malloc</span>(p*<span class=\"number\">10</span>*<span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>));</span><br><span class=\"line\">MPI_Gather(data, <span class=\"number\">10</span>, MPI_FLOAT, buf, <span class=\"number\">0</span>, MPI_FLOAT, <span class=\"number\">0</span>, comm);</span><br></pre></td></tr></table></div></figure>\n\n<h2 id=\"MPI-Allgather\"><code>MPI_Allgather</code><a href=\"mpi#MPI-Allgather\"></a></h2><p>多对多，数据收集</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Allgather</span><span class=\"params\">(<span class=\"keyword\">void</span> *sendbuf, <span class=\"keyword\">int</span> sendcount, MPI_Datatype sendtype,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                  <span class=\"keyword\">void</span> *recvbuf, <span class=\"keyword\">int</span> recvcount, MPI_Datatype recvtype, MPI_Comm comm)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> p, myrank;</span><br><span class=\"line\"><span class=\"keyword\">float</span> data[<span class=\"number\">10</span>];</span><br><span class=\"line\"><span class=\"keyword\">float</span> *buf;</span><br><span class=\"line\">MPI_Comm comm;</span><br><span class=\"line\">MPI_Init(&amp;argc, &amp;argv);</span><br><span class=\"line\">MPI_Comm_rank(comm, &amp;myrank);</span><br><span class=\"line\">MPI_Comm_size(comm, &amp;p);</span><br><span class=\"line\">buf = (<span class=\"keyword\">float</span>*)<span class=\"built_in\">malloc</span>(p*<span class=\"number\">10</span>*<span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>));</span><br><span class=\"line\">MPI_Gather(data, <span class=\"number\">10</span>, MPI_FLOAT, buf, <span class=\"number\">0</span>, MPI_FLOAT, comm);</span><br></pre></td></tr></table></div></figure>\n\n<h2 id=\"MPI-Scatter\"><code>MPI_Scatter</code><a href=\"mpi#MPI-Scatter\"></a></h2><p>一对多，数据散发，root进程将一个大的数据块分成小块分散发给各个进程（包括root进程自己），是数据收集的逆操作。</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Scatter</span><span class=\"params\">(<span class=\"keyword\">void</span> *sendbuf, <span class=\"keyword\">int</span> sendcnt, MPI_Datatype sendtype,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                <span class=\"keyword\">void</span> *recvbuf, <span class=\"keyword\">int</span> recvcount, MPI_Datatype recvtype, <span class=\"keyword\">int</span> root, MPI_Comm comm)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">int</span> p, myrank;</span><br><span class=\"line\"><span class=\"keyword\">float</span> data[<span class=\"number\">10</span>];</span><br><span class=\"line\"><span class=\"keyword\">float</span> *buf;</span><br><span class=\"line\">MPI_Comm comm;</span><br><span class=\"line\">MPI_Init(&amp;argc, &amp;argv);</span><br><span class=\"line\">MPI_Comm_rank(comm, &amp;myrank);</span><br><span class=\"line\">MPI_Comm_size(comm, &amp;p);</span><br><span class=\"line\"><span class=\"keyword\">if</span> (myrank == <span class=\"number\">0</span>)</span><br><span class=\"line\">    buf = (<span class=\"keyword\">float</span>*)<span class=\"built_in\">malloc</span>(p*<span class=\"number\">10</span>*<span class=\"keyword\">sizeof</span>(<span class=\"keyword\">float</span>));</span><br><span class=\"line\">MPI_Scatter(data, <span class=\"number\">10</span>, MPI_FLOAT, buf, <span class=\"number\">0</span>, MPI_FLOAT, <span class=\"number\">0</span>, comm);</span><br></pre></td></tr></table></div></figure>\n\n<h2 id=\"MPI-Alltoall\"><code>MPI_Alltoall</code><a href=\"mpi#MPI-Alltoall\"></a></h2><p>多对多，数据分发</p>\n<ul>\n<li>每个进程发送一个消息给n个进程，包括它自己，这n个消息的发送缓冲区中以标号的顺序有序地存放。</li>\n<li>一次全局交换中共有 <svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"2.449ex\" height=\"2.676ex\" style=\"vertical-align: -0.338ex;\" viewbox=\"0 -1006.6 1054.4 1152.1\" role=\"img\" focusable=\"false\" xmlns=\"http://www.w3.org/2000/svg\" aria-labelledby=\"MathJax-SVG-1-Title\">\n<title id=\"MathJax-SVG-1-Title\">n^2</title>\n<defs aria-hidden=\"true\">\n<path stroke-width=\"1\" id=\"E1-MJMATHI-6E\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"/>\n<path stroke-width=\"1\" id=\"E1-MJMAIN-32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"/>\n</defs>\n<g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"matrix(1 0 0 -1 0 0)\" aria-hidden=\"true\">\n <use xlink:href=\"#E1-MJMATHI-6E\" x=\"0\" y=\"0\"/>\n <use transform=\"scale(0.707)\" xlink:href=\"#E1-MJMAIN-32\" x=\"849\" y=\"583\"/>\n</g>\n</svg> 个消息进行通信。</li>\n</ul>\n<p><img src=\"mpi/mpi-alltoall.svg\" alt class=\"article-img\"></p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Alltoall</span><span class=\"params\">(<span class=\"keyword\">void</span> *sendbuf, <span class=\"keyword\">int</span> sendcount, MPI_Datatype sendtype,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">                 <span class=\"keyword\">void</span> *recvbuf, <span class=\"keyword\">int</span> recvcount, MPI_Datatype recvtype, MPI_Comm comm)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<h2 id=\"MPI-Reduce\"><code>MPI_Reduce</code><a href=\"mpi#MPI-Reduce\"></a></h2><p>简单归约，将通信域内每个进程输入缓冲区中的数据按给定的操作进行简单运算，并将结果返回到root进程的输出缓冲区中。</p>\n<ul>\n<li>归约操作可以使用MPI预定义的运算操作，也可以使用用户自定义的运算操作，但必须满足结合律。<ul>\n<li>创建自定义归约运算操作：<code>MPI_Op_create</code></li>\n<li>释放自定义的归约操作: <code>MPI_Op_free</code></li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Reduce</span><span class=\"params\">(<span class=\"keyword\">void</span> *sendbuf, <span class=\"keyword\">void</span> *recvbuf, <span class=\"keyword\">int</span> count, MPI_Datatype datatype, MPI_Op op, <span class=\"keyword\">int</span> root, MPI_Comm comm)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<ul>\n<li>参数 <code>recvbuf</code> 只对根进程有意义</li>\n<li>所有进程所提供的数据长度相同、类型相同</li>\n</ul>\n<p><img src=\"mpi/mpi-reduce.svg\" alt class=\"article-img\"></p>\n<p><strong>MPI归约预定义操作：</strong></p>\n<div class=\"article-bounded\"><div class=\"article-table\"><table>\n<thead>\n<tr>\n<th>操作</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>MPI_MAX</code></td>\n<td>最大值</td>\n</tr>\n<tr>\n<td><code>MPI_MIN</code></td>\n<td>最小值</td>\n</tr>\n<tr>\n<td><code>MPI_SUM</code></td>\n<td>求和</td>\n</tr>\n<tr>\n<td><code>MPI_PROD</code></td>\n<td>求积</td>\n</tr>\n<tr>\n<td><code>MPI_LAND</code></td>\n<td>逻辑与</td>\n</tr>\n<tr>\n<td><code>MPI_BAND</code></td>\n<td>按位与</td>\n</tr>\n<tr>\n<td><code>MPI_LOR</code></td>\n<td>逻辑或</td>\n</tr>\n<tr>\n<td><code>MPI_BOR</code></td>\n<td>按位或</td>\n</tr>\n<tr>\n<td><code>MPI_LXOR</code></td>\n<td>逻辑异或</td>\n</tr>\n<tr>\n<td><code>MPI_BXOR</code></td>\n<td>按位异或</td>\n</tr>\n<tr>\n<td><code>MPI_MAXLOC</code></td>\n<td>最大值及相应位置</td>\n</tr>\n<tr>\n<td><code>MPI_MINLOC</code></td>\n<td>最小值及相应位置</td>\n</tr>\n</tbody></table></div></div>\n<h2 id=\"MPI-Allreduce\"><code>MPI_Allreduce</code><a href=\"mpi#MPI-Allreduce\"></a></h2><figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Allreduce</span><span class=\"params\">(<span class=\"keyword\">void</span> *sendbuf, <span class=\"keyword\">void</span> *recvbuf, <span class=\"keyword\">int</span> count, MPI_Datatype datatype, MPI_Op op, MPI_Comm comm)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<ul>\n<li>所有进程的<code>recvbuf</code>将同时获得归约运算的结果</li>\n<li>相当于<code>MPI_Reduce</code>后再将结果进行一次广播</li>\n</ul>\n<p><img src=\"mpi/mpi-allreduce.svg\" alt class=\"article-img\"></p>\n<h2 id=\"MPI-Scan\"><code>MPI_Scan</code><a href=\"mpi#MPI-Scan\"></a></h2><p>前缀和计算</p>\n<ul>\n<li>每一个进程都对排在它前面的进程进行归约操作，操作结束后，第i个进程中的<code>recvbuf</code>中将包含前i个进程的归约结果。</li>\n<li>0号进程接收缓冲区中的数据就是其发送缓冲区的数据</li>\n</ul>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Scan</span><span class=\"params\">(<span class=\"keyword\">void</span> *sendbuf, <span class=\"keyword\">void</span> *recvbuf, <span class=\"keyword\">int</span> count, MPI_Datatype datatype, MPI_Op op, MPI_Comm comm)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<p><img src=\"mpi/mpi-scan.svg\" alt class=\"article-img\"></p>\n<h2 id=\"MPI-Barrier\"><code>MPI_Barrier</code><a href=\"mpi#MPI-Barrier\"></a></h2><p>MPI唯一的同步函数</p>\n<ul>\n<li>当通信域内所有进程都执行该函数时才返回，否则将一直等待</li>\n</ul>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Barrier</span><span class=\"params\">(MPI_Comm comm)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<h1 id=\"MPI派生数据类型\">MPI派生数据类型<a href=\"mpi#MPI派生数据类型\"></a></h1><p>派生数据类型可有效减少消息传递次数，增大通信粒度，同时可以避免或减少消息传递时数据在内存中的拷贝。</p>\n<p>主要思想：当一个发送数据的函数知道数据项集合的一些信息时，可以在发送前收集好这些数据，而不是在发送时临时抱佛脚；同理，接收数据的函数在接收数据时可以根据这些信息将数据项分发到正确的目标内存地址。</p>\n<div class=\"article-bounded\"><div class=\"article-table\"><table>\n<thead>\n<tr>\n<th>函数名</th>\n<th>含义</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>MPI_Type_contiguous</td>\n<td>定义由相同数据类型的元素组成的类型</td>\n</tr>\n<tr>\n<td>MPI_Type_vector</td>\n<td>定义由成块的元素组成的类型，块之间具有相同间隔</td>\n</tr>\n<tr>\n<td>MPI_Type_indexed</td>\n<td>定义由成块的元素组成的类型，块长度和偏移由参数指定</td>\n</tr>\n<tr>\n<td>MPI_Type_create_struct</td>\n<td>定义由不同数据类型的元素组成的类型</td>\n</tr>\n<tr>\n<td>MPI_Type_commit</td>\n<td>提交一个派生数据类型</td>\n</tr>\n<tr>\n<td>MPI_Type_free</td>\n<td>释放一个派生数据类型</td>\n</tr>\n<tr>\n<td>MPI_Get_address</td>\n<td>返回内存地址</td>\n</tr>\n</tbody></table></div></div>\n<h2 id=\"MPI-Type-contiguous\"><code>MPI_Type_contiguous</code><a href=\"mpi#MPI-Type-contiguous\"></a></h2><p>将一个已有的数据类型按顺序依次连续进行复制后的新类型。</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Type_contiguous</span><span class=\"params\">(<span class=\"keyword\">int</span> count, MPI_Datatype oldtype, MPI_Datatype *newtype)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<h2 id=\"MPI-Type-vector\"><code>MPI_Type_vector</code><a href=\"mpi#MPI-Type-vector\"></a></h2><p>复制一个数据类型到含有相等大小块的空间，每个块通过连接相同数量的就数据类型的拷贝来获得块与块之间的空间是旧数据类型的extent的倍数。</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Type_vector</span><span class=\"params\">(<span class=\"keyword\">int</span> count, <span class=\"keyword\">int</span> blocklength, <span class=\"keyword\">int</span> stride, MPI_Datatype oldtype, MPI_Datatype *newtype)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<ul>\n<li><code>count</code>: 块的数量</li>\n<li><code>blocklength</code>: 块中所包含的元素个数</li>\n<li><code>stride</code>: 各块第一个元素之间相隔的元素个数</li>\n</ul>\n<h2 id=\"MPI-Type-indexed\"><code>MPI_Type_indexed</code><a href=\"mpi#MPI-Type-indexed\"></a></h2><p>复制一个旧数据类型到块序列中，每个块可以包含不同的拷贝数量和具有不同的偏移，所有的块偏移都是旧数据类型extent的倍数</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Type_indexed</span><span class=\"params\">(<span class=\"keyword\">int</span> count, <span class=\"keyword\">int</span> *array_of_blocklengths, <span class=\"keyword\">int</span> *array_of_displacements, MPI_Datatype oldtype, MPI_Datatype *newtype)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<ul>\n<li><code>count</code>: 块的数量</li>\n<li><code>array_of_blocklengths</code>: 每个块所含的元素个数</li>\n<li><code>array_of_displacements</code>: 各块偏移值</li>\n</ul>\n<h2 id=\"MPI-Type-create-struct\"><code>MPI_Type_create_struct</code><a href=\"mpi#MPI-Type-create-struct\"></a></h2><p>最通用的类型生成器</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Type_create_struct</span><span class=\"params\">(<span class=\"keyword\">int</span> count, <span class=\"keyword\">int</span> *array_of_blocklengths, MPI_Aint *array_of_displacements, MPI_Datatype *array_of_types, MPI_Datatype *newtype)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<ul>\n<li><code>count</code>: 块的数量</li>\n<li><code>array_of_blocklengths</code>: 每个块中所含的元素个数</li>\n<li><code>array_of_displacements</code>: 每个块偏移字节数,<code>MPI_Aint</code>是一个足够存储系统地址的大整数类型</li>\n<li><code>array_of_types</code>: 每个块中元素的类型</li>\n</ul>\n<h2 id=\"MPI-Type-commit\"><code>MPI_Type_commit</code><a href=\"mpi#MPI-Type-commit\"></a></h2><p>类型提交，新类型在通信前必须提交</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Type_commit</span><span class=\"params\">(MPI_Datatype *datatype)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<h2 id=\"MPI-Type-free\"><code>MPI_Type_free</code><a href=\"mpi#MPI-Type-free\"></a></h2><p>释放类型</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Type_free</span><span class=\"params\">(MPI_Datatype *datatype)</span></span></span><br></pre></td></tr></table></div></figure>\n\n<h2 id=\"MPI-Get-address\"><code>MPI_Get_address</code><a href=\"mpi#MPI-Get-address\"></a></h2><p>返回内存地址</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">MPI_Get_address</span><span class=\"params\">(<span class=\"keyword\">void</span> *location, MPI_Aint *address)</span></span></span><br></pre></td></tr></table></div></figure>\n\n","prev":{"title":"强连通分量","link":"strongly-connected-component"},"next":{"title":"大数据量下均值和方差的增量计算","link":"big-data-mean-std"},"plink":"https://yuxinzhao.net/mpi/","toc":[{"title":"安装","id":"安装","index":"1"},{"title":"第一个MPI程序","id":"第一个MPI程序","index":"2"},{"title":"我是谁？世界有多大？","id":"我是谁？世界有多大？","index":"3"},{"title":"MPI数据类型","id":"MPI数据类型","index":"4","children":[{"title":"MPI预定义数据类型","id":"MPI预定义数据类型","index":"4.1"},{"title":"MPI常用常量","id":"MPI常用常量","index":"4.2"}]},{"title":"消息传递","id":"消息传递","index":"5","children":[{"title":"<code>MPI_Send</code>","id":"MPI-Send","index":"5.1"},{"title":"<code>MPI_Recv</code>","id":"MPI-Recv","index":"5.2"}]},{"title":"通信域","id":"通信域","index":"6"},{"title":"消息状态","id":"消息状态","index":"7"},{"title":"点对点通信","id":"点对点通信","index":"8","children":[{"title":"通信模式","id":"通信模式","index":"8.1"},{"title":"通信机制","id":"通信机制","index":"8.2","children":[{"title":"阻塞通信","id":"阻塞通信","index":"8.2.1"},{"title":"非阻塞通信","id":"非阻塞通信","index":"8.2.2"}]},{"title":"消息探测","id":"消息探测","index":"8.3"},{"title":"<code>MPI_Sendrecv</code>","id":"MPI-Sendrecv","index":"8.4"},{"title":"点对点通信应用示例","id":"点对点通信应用示例","index":"8.5","children":[{"title":"流水线型","id":"流水线型","index":"8.5.1"},{"title":"双缓冲流水线型","id":"双缓冲流水线型","index":"8.5.2"}]}]},{"title":"聚合通信","id":"聚合通信","index":"9","children":[{"title":"<code>MPI_Bcast</code>","id":"MPI-Bcast","index":"9.1"},{"title":"<code>MPI_Gather</code>","id":"MPI-Gather","index":"9.2"},{"title":"<code>MPI_Allgather</code>","id":"MPI-Allgather","index":"9.3"},{"title":"<code>MPI_Scatter</code>","id":"MPI-Scatter","index":"9.4"},{"title":"<code>MPI_Alltoall</code>","id":"MPI-Alltoall","index":"9.5"},{"title":"<code>MPI_Reduce</code>","id":"MPI-Reduce","index":"9.6"},{"title":"<code>MPI_Allreduce</code>","id":"MPI-Allreduce","index":"9.7"},{"title":"<code>MPI_Scan</code>","id":"MPI-Scan","index":"9.8"},{"title":"<code>MPI_Barrier</code>","id":"MPI-Barrier","index":"9.9"}]},{"title":"MPI派生数据类型","id":"MPI派生数据类型","index":"10","children":[{"title":"<code>MPI_Type_contiguous</code>","id":"MPI-Type-contiguous","index":"10.1"},{"title":"<code>MPI_Type_vector</code>","id":"MPI-Type-vector","index":"10.2"},{"title":"<code>MPI_Type_indexed</code>","id":"MPI-Type-indexed","index":"10.3"},{"title":"<code>MPI_Type_create_struct</code>","id":"MPI-Type-create-struct","index":"10.4"},{"title":"<code>MPI_Type_commit</code>","id":"MPI-Type-commit","index":"10.5"},{"title":"<code>MPI_Type_free</code>","id":"MPI-Type-free","index":"10.6"},{"title":"<code>MPI_Get_address</code>","id":"MPI-Get-address","index":"10.7"}]}],"reward":true,"copyright":{"author":"Yuxin Zhao","link":"<a href=\"https://yuxinzhao.net/mpi/\" title=\"MPI基础\">https://yuxinzhao.net/mpi/</a>","license":"Attribution-NonCommercial-NoDerivatives 4.0 International (<a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\" rel=\"external nofollow noopener\" target=\"_blank\">CC BY-NC-ND 4.0</a>)"}}