{"title":"使用TensorRT加速PyTorch模型","date":"2021-04-16T13:55:20.000Z","link":"speed-up-pytorch-model-using-tensorrt","comments":true,"tags":["pytorch","tensorrt"],"categories":["machine-learning"],"updated":"2022-01-04T08:35:48.647Z","content":"<p>本文将介绍使用TensorRT推理引擎对PyTorch模型进行加速，便于算法的部署。</p>\n<a id=\"more\"></a>\n\n\n\n<h1 id=\"PyTorch模型转换成TensorRT引擎的路径\">PyTorch模型转换成TensorRT引擎的路径<a href=\"speed-up-pytorch-model-using-tensorrt#PyTorch模型转换成TensorRT引擎的路径\"></a></h1><p>目前，PyTorch模型转TensorRT需要借助ONNX作为中间的交换格式，先将PyTorch模型转换成ONNX模型，再将ONNX模型转换成TensorRT引擎。</p>\n<h1 id=\"环境准备\">环境准备<a href=\"speed-up-pytorch-model-using-tensorrt#环境准备\"></a></h1><p>系统：Ubuntu18.04</p>\n<ol>\n<li><p>从<a href=\"https://developer.nvidia.com/zh-cn/tensorrt\" target=\"_blank\" rel=\"noopener\">TensorRT官网</a>下载对应版本的TensorRT安装包。本例中下载到的是<code>TensorRT-7.2.3.4.Ubuntu-18.04.x86_64-gnu.cuda-11.1.cudnn8.1.tar.gz</code>。</p>\n</li>\n<li><p>将压缩包解压到<code>/opt</code>目录下。</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tar xzvf TensorRT-7.2.3.4.Ubuntu-18.04.x86_64-gnu.cuda-11.1.cudnn8.1.tar.gz -C /opt</span><br></pre></td></tr></table></div></figure>\n</li>\n<li><p>设置环境变量</p>\n<p>将以下两条放入<code>~/.bashrc</code>中。</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/TensorRT-7.2.3.4/lib:/usr/local/cuda/lib64</span><br><span class=\"line\">export PATH=$PATH:/opt/TensorRT-7.2.3.4/bin</span><br></pre></td></tr></table></div></figure>\n\n\n</li>\n</ol>\n<p>   将其生效。</p>\n   <figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">source ~/.bashrc</span><br></pre></td></tr></table></div></figure>\n\n<ol start=\"4\">\n<li><p>安装TensorRT的python包及其他辅助python包</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install /opt/TensorRT-7.2.3.4/python/tensorrt-7.2.3.4-cp38-none-linux_x86_64.whl</span><br><span class=\"line\">pip install /opt/TensorRT-7.2.3.4/uff/uff-0.6.9-py2.py3-none-any.whl</span><br><span class=\"line\">pip install /opt/TensorRT-7.2.3.4/graphsurgeon/graphsurgeon-0.4.5-py2.py3-none-any.whl</span><br><span class=\"line\">pip install /opt/TensorRT-7.2.3.4/onnx_graphsurgeon/onnx_graphsurgeon-0.2.6-py2.py3-none-any.whl</span><br></pre></td></tr></table></div></figure>\n</li>\n<li><p>安装其他必要的库</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install -i https://mirrors.aliyun.com/pypi/simple pycuda onnx-simplifier</span><br><span class=\"line\"></span><br><span class=\"line\">sed -i 's/archive.ubuntu.com/mirrors.aliyun.com/g' /etc/apt/sources.list \\</span><br><span class=\"line\">&amp;&amp; apt-get update -y \\</span><br><span class=\"line\">&amp;&amp; apt-get install -y -f libglib2.0-0 libsm6 libxrender1 libxext6 libgl1-mesa-glx \\</span><br><span class=\"line\">&amp;&amp; pip install -i https://mirrors.aliyun.com/pypi/simple opencv-python</span><br></pre></td></tr></table></div></figure>\n\n\n\n</li>\n</ol>\n<h1 id=\"PyTorch转换成ONNX\">PyTorch转换成ONNX<a href=\"speed-up-pytorch-model-using-tensorrt#PyTorch转换成ONNX\"></a></h1><p>ONNX格式是本身是由Facebook公司参与开发的，受到PyTorch的原生支持，可用<code>torch.onnx</code>模块进行ONNX的导出。</p>\n<h2 id=\"准备待转换的PyTorch模型\">准备待转换的PyTorch模型<a href=\"speed-up-pytorch-model-using-tensorrt#准备待转换的PyTorch模型\"></a></h2><p>首先构建好模型并加载上权重，还可以将标准化、阈值化等预处理、后处理步骤也加入到模型中，将尽可能多的步骤放到ONNX中，后续可以一并转换成TensorRT引擎，避免因预处理、后处理步骤放在了CPU上执行或使用PyTorch实现而造成的数据在GPU和CPU上频繁传输导致算法速度降低。</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.onnx</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> ...</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">OnnxModel</span><span class=\"params\">(nn.Module)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, cfg)</span>:</span></span><br><span class=\"line\">        super().__init__()</span><br><span class=\"line\">        self.model = build_model(cfg)</span><br><span class=\"line\">        self.model.load_state_dict(torch.load(cfg.MODEL.WEIGHTS))</span><br><span class=\"line\">        self.num_classes = <span class=\"number\">2</span></span><br><span class=\"line\">        <span class=\"keyword\">assert</span> self.num_classes == <span class=\"number\">2</span>, <span class=\"string\">\"the OnnxModel implementation is only for num_classes == 2\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, images, images_wh, pixel_mean_std, score_thresholds)</span>:</span></span><br><span class=\"line\">        images = (images - pixel_mean_std[:, :<span class=\"number\">1</span>].view(<span class=\"number\">-1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>)) / pixel_mean_std[:, <span class=\"number\">1</span>:].view(<span class=\"number\">-1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">        bboxes, classification = self.model(images)</span><br><span class=\"line\"></span><br><span class=\"line\">        batch_size, num_boxes = [int(i) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> bboxes.shape[:<span class=\"number\">2</span>]]</span><br><span class=\"line\">        h, w = [int(i) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> images.shape[<span class=\"number\">-2</span>:]]</span><br><span class=\"line\">        standard_wh = torch.from_numpy(np.array([w, h]).reshape(<span class=\"number\">1</span>, <span class=\"number\">2</span>)).cuda()</span><br><span class=\"line\"></span><br><span class=\"line\">        wh_scale = images_wh.max(<span class=\"number\">1</span>, keepdims=<span class=\"literal\">True</span>)[<span class=\"number\">0</span>] / (images_wh * standard_wh)</span><br><span class=\"line\"></span><br><span class=\"line\">        bboxes *= wh_scale[:, <span class=\"literal\">None</span>, :].repeat(<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">        bboxes = torch.clamp(bboxes, min=<span class=\"number\">0</span>, max=<span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        classification_class0 = classification[:, :, <span class=\"number\">0</span>]</span><br><span class=\"line\">        classification_class1 = classification[:, :, <span class=\"number\">1</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">        is_valid_boxes = (bboxes[:, :, <span class=\"number\">0</span>] &lt; bboxes[:, :, <span class=\"number\">2</span>]) &amp; (bboxes[:, :, <span class=\"number\">1</span>] &lt; bboxes[:, :, <span class=\"number\">3</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">        is_class0_over_threshold = classification_class0 &gt; score_thresholds[<span class=\"number\">0</span>]</span><br><span class=\"line\">        is_class1_over_threshold = classification_class1 &gt; score_thresholds[<span class=\"number\">1</span>]</span><br><span class=\"line\">        is_0_classes = classification_class0 &gt; classification_class1</span><br><span class=\"line\"></span><br><span class=\"line\">        is_class0_score_save = is_class0_over_threshold &amp; is_0_classes &amp; is_valid_boxes</span><br><span class=\"line\">        is_class1_score_save = is_class1_over_threshold &amp; ~is_0_classes &amp; is_valid_boxes</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">        index_score_save = torch.cat([is_class0_score_save.float()[:, :, <span class=\"literal\">None</span>], is_class1_score_save.float()[:, :, <span class=\"literal\">None</span>]], dim=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        classification *= index_score_save</span><br><span class=\"line\"></span><br><span class=\"line\">        images_wh_helper = images_wh[:, <span class=\"literal\">None</span>, :].repeat(<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> bboxes, classification, images_wh_helper</span><br></pre></td></tr></table></div></figure>\n\n<p>受TensorRT的限制，某些操作不能在PyTorch中使用，需要用其他的形式进行代替：</p>\n<ol>\n<li>不能够对Boolean类型张量进行索引或切片。TensorRT不允许对Boolean类型的张量进行索引或切片，因此一个替代的方案是在需要进行索引或切片前，先将Boolean类型张量转换成int类型张量或float类型张量，再进行索引或切片。</li>\n</ol>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">temp = bboxes[:, :, <span class=\"number\">0</span>:<span class=\"number\">2</span>] &lt; bboxes[:, :, <span class=\"number\">2</span>:<span class=\"number\">4</span>]</span><br><span class=\"line\">is_valid_boxes = temp[:, :, <span class=\"number\">0</span>] &amp; temp[:, :, <span class=\"number\">1</span>]  <span class=\"comment\"># 该操作对布尔类型的张量进行了索引，可以正常转换成ONNX，但ONNX转换成TensorRT将会失败，因尽可能避免</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 可改成</span></span><br><span class=\"line\">is_valid_boxes = (bboxes[:, :, <span class=\"number\">0</span>] &lt; bboxes[:, :, <span class=\"number\">2</span>]) &amp; (bboxes[:, :, <span class=\"number\">1</span>] &lt; bboxes[:, :, <span class=\"number\">3</span>])</span><br></pre></td></tr></table></div></figure>\n\n<ol start=\"2\">\n<li>不能够给张量的切片赋值。</li>\n</ol>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bboxes[:, :, <span class=\"number\">0</span>::<span class=\"number\">2</span>] /= w  <span class=\"comment\"># 此操作单独改变了切片中的值，无法转换成ONNX</span></span><br><span class=\"line\">bboxes[:, :, <span class=\"number\">1</span>::<span class=\"number\">2</span>] /= h</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 可改成</span></span><br><span class=\"line\">bboxes /= torch.cat([w, h]).repeat(<span class=\"number\">1</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br></pre></td></tr></table></div></figure>\n\n<h2 id=\"转换PyTorch到ONNX\">转换PyTorch到ONNX<a href=\"speed-up-pytorch-model-using-tensorrt#转换PyTorch到ONNX\"></a></h2><p>主要使用<code>torch.onnx.export</code>接口将PyTorch模型转换成ONNX。</p>\n<p>将待转换的模型准备好，放到gpu设备上，并准备好一个输入的样本用于运行生成静态图。</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">device = <span class=\"string\">\"cuda:0\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">model = OnnxModel(cfg)</span><br><span class=\"line\">model.to(device)</span><br><span class=\"line\"></span><br><span class=\"line\">model.eval()</span><br><span class=\"line\"></span><br><span class=\"line\">batch_size = <span class=\"number\">2</span></span><br><span class=\"line\"></span><br><span class=\"line\">image_shape = (batch_size, cfg.MODEL.INPUT.IN_CHANNELS, *cfg.MODEL.INPUT.SIZE)</span><br><span class=\"line\"></span><br><span class=\"line\">images = torch.randn(*image_shape).to(device) * <span class=\"number\">255</span></span><br><span class=\"line\">pixel_mean_std = torch.Tensor(batch_size * [<span class=\"number\">0.0</span>, <span class=\"number\">1.0</span>]).view(batch_size, <span class=\"number\">2</span>).to(device)</span><br><span class=\"line\">score_thresholds = torch.Tensor([<span class=\"number\">0.2</span>, <span class=\"number\">0.2</span>]).to(device)</span><br><span class=\"line\">images_wh = torch.Tensor(batch_size * [<span class=\"number\">640</span>, <span class=\"number\">480</span>]).view(batch_size, <span class=\"number\">2</span>).to(device)</span><br><span class=\"line\"></span><br><span class=\"line\">model(images, images_wh, pixel_mean_std, score_thresholds)</span><br><span class=\"line\"></span><br><span class=\"line\">torch.onnx.export(</span><br><span class=\"line\">    model,</span><br><span class=\"line\">    (images, images_wh, pixel_mean_std, score_thresholds),</span><br><span class=\"line\">    out_onnx_path,</span><br><span class=\"line\">    export_params=<span class=\"literal\">True</span>,</span><br><span class=\"line\">    input_names=[<span class=\"string\">'images'</span>, <span class=\"string\">'images_width_height'</span>, <span class=\"string\">'pixel_mean_std'</span>, <span class=\"string\">'score_thresholds'</span>],</span><br><span class=\"line\">    output_names=[<span class=\"string\">'bboxes'</span>, <span class=\"string\">'classification'</span>, <span class=\"string\">'images_width_height_helper'</span>],</span><br><span class=\"line\">    do_constant_folding=<span class=\"literal\">True</span>,</span><br><span class=\"line\">    verbose=<span class=\"literal\">True</span>,</span><br><span class=\"line\">    opset_version=<span class=\"number\">12</span>,</span><br><span class=\"line\">    dynamic_axes=&#123;</span><br><span class=\"line\">        <span class=\"string\">\"images\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"number\">0</span>: <span class=\"string\">'batch_size'</span>,</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">\"images_width_height\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"number\">0</span>: <span class=\"string\">'batch_size'</span>,</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">\"pixel_mean_std\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"number\">0</span>: <span class=\"string\">'batch_size'</span>,</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">\"bboxes\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"number\">0</span>: <span class=\"string\">'batch_size'</span>,</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">\"classification\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"number\">0</span>: <span class=\"string\">'batch_size'</span>,</span><br><span class=\"line\">        &#125;,</span><br><span class=\"line\">        <span class=\"string\">\"images_width_height_helper\"</span>: &#123;</span><br><span class=\"line\">            <span class=\"number\">0</span>: <span class=\"string\">'batch_size'</span>,</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;,</span><br><span class=\"line\">)</span><br></pre></td></tr></table></div></figure>\n\n<h2 id=\"简化静态图\">简化静态图<a href=\"speed-up-pytorch-model-using-tensorrt#简化静态图\"></a></h2><p>由于PyTorch底层实现上产生的ONNX静态图中还会存在着很多可以合并优化的步骤，其中有些步骤会在ONNX转换成TensorRT的步骤中出错，因此需要将得到的ONNX模型进行简化。简化的工具可使用python包<code>onnx-simplifier</code>。</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> onnxsim</span><br><span class=\"line\">model_opt, check_ok = onnxsim.simplify(</span><br><span class=\"line\">    out_onnx_path,</span><br><span class=\"line\">    dynamic_input_shape=<span class=\"literal\">True</span>,</span><br><span class=\"line\">    input_shapes=&#123;</span><br><span class=\"line\">        <span class=\"string\">'images'</span>: image_shape,</span><br><span class=\"line\">        <span class=\"string\">'images_width_height'</span>: (batch_size, <span class=\"number\">2</span>),</span><br><span class=\"line\">        <span class=\"string\">'pixel_mean_std'</span>: (batch_size, <span class=\"number\">2</span>),</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"keyword\">if</span> check_ok:</span><br><span class=\"line\">    onnx.save(model_opt, out_onnx_path)</span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\">    <span class=\"keyword\">raise</span> Exception(<span class=\"string\">\"Check failed\"</span>)</span><br></pre></td></tr></table></div></figure>\n\n<p>注意到此时我们生成的静态图仍然是动态batchsize的。</p>\n<h1 id=\"ONNX转换成TensorRT\">ONNX转换成TensorRT<a href=\"speed-up-pytorch-model-using-tensorrt#ONNX转换成TensorRT\"></a></h1><p>上一步中我们得到的onnx模型是动态大小的，直接转换成TensorRT模型需要使用TensorRT的dynamic shape特性，但是该特性下会有很多问题，部分模块会无法使用，因此先介绍如何转换成固定张量维度的TensorRT引擎。</p>\n<h2 id=\"添加非极大值抑制插件\">添加非极大值抑制插件<a href=\"speed-up-pytorch-model-using-tensorrt#添加非极大值抑制插件\"></a></h2><p>由于非极大值抑制操作无法直接从PyTorch转换到ONNX，因此需要手动添加非极大值抑制，可以通过TensorRT提供的插件机制，实现无法转换的部分。由于TensorRT官方提供了<a href=\"https://github.com/NVIDIA/TensorRT/tree/master/plugin\" target=\"_blank\" rel=\"noopener\">各种插件</a>，其中包括了非极大值抑制，因此可以很方便地使用非极大值抑制插件而不必自己编写。</p>\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">add_nms</span><span class=\"params\">(onnx_model, nms_iou_threshold, nms_top_k, nms_keep_top_k)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">import</span> onnx_graphsurgeon <span class=\"keyword\">as</span> gs</span><br><span class=\"line\">    graph = gs.import_onnx(onnx_model)</span><br><span class=\"line\"></span><br><span class=\"line\">    bboxes_tensor, classification_tensor, images_width_height_helper_tensor = graph.outputs</span><br><span class=\"line\"></span><br><span class=\"line\">    batch_size = bboxes_tensor.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># add reshape</span></span><br><span class=\"line\">    bboxes_new_shape = gs.Constant(</span><br><span class=\"line\">        <span class=\"string\">\"bboxes_new_shape\"</span>,</span><br><span class=\"line\">        values=np.array([bboxes_tensor.shape[<span class=\"number\">0</span>], bboxes_tensor.shape[<span class=\"number\">1</span>], <span class=\"number\">1</span>, bboxes_tensor.shape[<span class=\"number\">2</span>]], dtype=np.int64),</span><br><span class=\"line\">    )</span><br><span class=\"line\">    bboxes_new_tensor = gs.Variable(</span><br><span class=\"line\">        <span class=\"string\">\"bboxes_new\"</span>,</span><br><span class=\"line\">        shape=tuple(int(i) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> bboxes_new_shape.values),</span><br><span class=\"line\">        dtype=bboxes_tensor.dtype,</span><br><span class=\"line\">    )</span><br><span class=\"line\">    bboxes_reshape_node = gs.Node(</span><br><span class=\"line\">        op=<span class=\"string\">\"Reshape\"</span>,</span><br><span class=\"line\">        inputs=[bboxes_tensor, bboxes_new_shape],</span><br><span class=\"line\">        outputs=[bboxes_new_tensor],</span><br><span class=\"line\">    )</span><br><span class=\"line\">    graph.nodes.append(bboxes_reshape_node)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># add nms</span></span><br><span class=\"line\">    nms_attrs = &#123;</span><br><span class=\"line\">        <span class=\"string\">\"shareLocation\"</span>: <span class=\"literal\">True</span>,</span><br><span class=\"line\">        <span class=\"string\">\"backgroundLabelId\"</span>: <span class=\"number\">-1</span>,</span><br><span class=\"line\">        <span class=\"string\">\"numClasses\"</span>: <span class=\"number\">2</span>,</span><br><span class=\"line\">        <span class=\"string\">\"topK\"</span>: nms_top_k,</span><br><span class=\"line\">        <span class=\"string\">\"keepTopK\"</span>: nms_keep_top_k,</span><br><span class=\"line\">        <span class=\"string\">\"scoreThreshold\"</span>: <span class=\"number\">0.01</span>,</span><br><span class=\"line\">        <span class=\"string\">\"iouThreshold\"</span>: nms_iou_threshold,</span><br><span class=\"line\">        <span class=\"string\">\"isNormalized\"</span>: <span class=\"literal\">True</span>,</span><br><span class=\"line\">        <span class=\"string\">\"clipBoxes\"</span>: <span class=\"literal\">True</span>,</span><br><span class=\"line\">        <span class=\"string\">\"plugin_version\"</span>: <span class=\"string\">\"1\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"plugin_namespace\"</span>: <span class=\"string\">\"\"</span>,</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    num_detections_tensor = gs.Variable(</span><br><span class=\"line\">        <span class=\"string\">\"num_detections\"</span>,</span><br><span class=\"line\">        shape=(batch_size, <span class=\"number\">1</span>),</span><br><span class=\"line\">        dtype=np.int32,</span><br><span class=\"line\">    )</span><br><span class=\"line\">    nmsed_boxes_norm_tensor = gs.Variable(</span><br><span class=\"line\">        <span class=\"string\">\"nmsed_boxes_norm\"</span>,</span><br><span class=\"line\">        shape=(batch_size, nms_attrs[<span class=\"string\">'keepTopK'</span>], <span class=\"number\">4</span>),</span><br><span class=\"line\">        dtype=np.float32,</span><br><span class=\"line\">    )</span><br><span class=\"line\">    nmsed_scores_tensor = gs.Variable(</span><br><span class=\"line\">        <span class=\"string\">\"nmsed_scores\"</span>,</span><br><span class=\"line\">        shape=(batch_size, nms_attrs[<span class=\"string\">'keepTopK'</span>]),</span><br><span class=\"line\">        dtype=np.float32,</span><br><span class=\"line\">    )</span><br><span class=\"line\">    nmsed_classes_tensor = gs.Variable(</span><br><span class=\"line\">        <span class=\"string\">\"nmsed_classes\"</span>,</span><br><span class=\"line\">        shape=(batch_size, nms_attrs[<span class=\"string\">'keepTopK'</span>]),</span><br><span class=\"line\">        dtype=np.float32,</span><br><span class=\"line\">    )</span><br><span class=\"line\">    nms_node = gs.Node(</span><br><span class=\"line\">        op=<span class=\"string\">\"BatchedNMS_TRT\"</span>,</span><br><span class=\"line\">        name=<span class=\"string\">'NMS'</span>,</span><br><span class=\"line\">        attrs=nms_attrs,</span><br><span class=\"line\">        inputs=[bboxes_new_tensor, classification_tensor],</span><br><span class=\"line\">        outputs=[num_detections_tensor, nmsed_boxes_norm_tensor, nmsed_scores_tensor, nmsed_classes_tensor],</span><br><span class=\"line\">    )</span><br><span class=\"line\">    graph.nodes.append(nms_node)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">#rescale box xyxy from (1, 1) to (w, h)</span></span><br><span class=\"line\">    nmsed_boxes_tensor = gs.Variable(</span><br><span class=\"line\">        <span class=\"string\">\"nmsed_boxes\"</span>,</span><br><span class=\"line\">        shape=(batch_size, nms_attrs[<span class=\"string\">'keepTopK'</span>], <span class=\"number\">4</span>),</span><br><span class=\"line\">        dtype=np.float32,</span><br><span class=\"line\">    )</span><br><span class=\"line\">    scale_node = gs.Node(</span><br><span class=\"line\">        op=<span class=\"string\">\"Mul\"</span>,</span><br><span class=\"line\">        name=<span class=\"string\">\"scale_width_height\"</span>,</span><br><span class=\"line\">        inputs=[nmsed_boxes_norm_tensor, images_width_height_helper_tensor],</span><br><span class=\"line\">        outputs=[nmsed_boxes_tensor],</span><br><span class=\"line\">    )</span><br><span class=\"line\">    graph.nodes.append(scale_node)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">#nmsed_boxes_tensor = nmsed_boxes_norm_tensor</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># redefine output</span></span><br><span class=\"line\">    graph.outputs = [num_detections_tensor, nmsed_boxes_tensor, nmsed_scores_tensor, nmsed_classes_tensor]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    graph.cleanup().toposort()</span><br><span class=\"line\">    onnx_model = gs.export_onnx(graph)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> onnx_model</span><br></pre></td></tr></table></div></figure>\n\n<h2 id=\"将ONNX从动态形状转换成固定形状\">将ONNX从动态形状转换成固定形状<a href=\"speed-up-pytorch-model-using-tensorrt#将ONNX从动态形状转换成固定形状\"></a></h2><figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> onnxsim</span><br><span class=\"line\">model_opt, check_ok = onnxsim.simplify(</span><br><span class=\"line\">    base_onnx_file_path,</span><br><span class=\"line\">    dynamic_input_shape=<span class=\"literal\">False</span>,</span><br><span class=\"line\">    input_shapes=&#123;</span><br><span class=\"line\">        <span class=\"string\">'images'</span>: image_shape,</span><br><span class=\"line\">        <span class=\"string\">'images_width_height'</span>: (image_shape[<span class=\"number\">0</span>], <span class=\"number\">2</span>),</span><br><span class=\"line\">        <span class=\"string\">'pixel_mean_std'</span>: (image_shape[<span class=\"number\">0</span>], <span class=\"number\">2</span>),</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">)</span><br><span class=\"line\"><span class=\"keyword\">if</span> check_ok:</span><br><span class=\"line\">    print(<span class=\"string\">\"success batchlize\"</span>)</span><br><span class=\"line\">    model_opt = add_nms(model_opt, nms_iou_threshold, nms_top_k, nms_keep_top_k)</span><br><span class=\"line\">    print(<span class=\"string\">\"success add nms\"</span>)</span><br><span class=\"line\">    onnx.save(model_opt, out_onnx_file_path)</span><br><span class=\"line\"><span class=\"keyword\">else</span>:</span><br><span class=\"line\">    <span class=\"keyword\">raise</span> Exception(<span class=\"string\">\"Check failed\"</span>)</span><br></pre></td></tr></table></div></figure>\n\n<h2 id=\"转换ONNX到TensorRT\">转换ONNX到TensorRT<a href=\"speed-up-pytorch-model-using-tensorrt#转换ONNX到TensorRT\"></a></h2><figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TRT_LOGGER = trt.Logger()</span><br><span class=\"line\">trt.init_libnvinfer_plugins(TRT_LOGGER, <span class=\"string\">\"\"</span>)</span><br><span class=\"line\">explicit_batch = <span class=\"number\">1</span> &lt;&lt; (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">build_engine</span><span class=\"params\">(max_batch_size, onnx_file_path, engine_file_path, fp16_mode=False)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\" Take an ONNX file and creates a TensorRT engine to run inference with\"\"\"</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> trt.Builder(TRT_LOGGER) <span class=\"keyword\">as</span> builder, \\</span><br><span class=\"line\">            builder.create_network(explicit_batch) <span class=\"keyword\">as</span> network, \\</span><br><span class=\"line\">            trt.OnnxParser(network, TRT_LOGGER) <span class=\"keyword\">as</span> parser:</span><br><span class=\"line\"></span><br><span class=\"line\">        builder.max_workspace_size = <span class=\"number\">1</span> &lt;&lt; <span class=\"number\">30</span>  <span class=\"comment\"># your workspace size 1GiB</span></span><br><span class=\"line\">        builder.max_batch_size = max_batch_size</span><br><span class=\"line\">        builder.fp16_mode = fp16_mode</span><br><span class=\"line\">        builder.int8_mode = <span class=\"literal\">False</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># Parse model file</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> os.path.exists(onnx_file_path):</span><br><span class=\"line\">            quit(<span class=\"string\">\"ONNX file &#123;&#125; not found\"</span>.format(onnx_file_path))</span><br><span class=\"line\"></span><br><span class=\"line\">        print(<span class=\"string\">\"Loading ONNX file from path &#123;&#125; ...\"</span>.format(onnx_file_path))</span><br><span class=\"line\">        <span class=\"keyword\">with</span> open(onnx_file_path, <span class=\"string\">'rb'</span>) <span class=\"keyword\">as</span> model:</span><br><span class=\"line\">            print(<span class=\"string\">\"Beginning ONNX file parsing\"</span>)</span><br><span class=\"line\">            parser.parse(model.read())</span><br><span class=\"line\"></span><br><span class=\"line\">        print(<span class=\"string\">\"Completed parsing of ONNX file\"</span>)</span><br><span class=\"line\">        print(<span class=\"string\">\"Building an engine from file &#123;&#125;; this may take a while...\"</span>.format(onnx_file_path))</span><br><span class=\"line\"></span><br><span class=\"line\">        engine = builder.build_cuda_engine(network)</span><br><span class=\"line\">        print(<span class=\"string\">\"Completed creating Engine\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">with</span> open(engine_file_path, <span class=\"string\">'wb'</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">            f.write(engine.serialize())</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">generate_engine_from_onnx</span><span class=\"params\">(batch_size, nms_iou_threshold, nms_top_k, nms_keep_top_k)</span>:</span></span><br><span class=\"line\">    cfg = get_cfg(<span class=\"string\">'config.yaml'</span>)</span><br><span class=\"line\">    base_onnx_file_path = cfg.MODEL.BASE_ONNX_WEIGHTS(cfg)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> os.path.exists(base_onnx_file_path):</span><br><span class=\"line\">        <span class=\"keyword\">raise</span> FileNotFoundError(<span class=\"string\">\"please generate base onnx file firstly.\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    cfg.MODEL.BATCH_SIZE = batch_size</span><br><span class=\"line\">    image_shape = (batch_size, cfg.MODEL.INPUT.IN_CHANNELS, *cfg.MODEL.INPUT.SIZE)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> nms_iou_threshold <span class=\"keyword\">is</span> <span class=\"literal\">None</span>:</span><br><span class=\"line\">        nms_iou_threshold = cfg.MODEL.NMS_THRESHOLD</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        cfg.MODEL.NMS_THRESHOLD = nms_iou_threshold</span><br><span class=\"line\">    out_onnx_file_path = cfg.MODEL.ONNX_WEIGHTS(cfg)</span><br><span class=\"line\">    out_engine_file_path = cfg.MODEL.TENSORRT_WEIGHTS(cfg)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> os.path.exists(out_onnx_file_path):</span><br><span class=\"line\">        <span class=\"keyword\">from</span> .modify_onnx <span class=\"keyword\">import</span> build_onnx_file</span><br><span class=\"line\">        build_onnx_file(base_onnx_file_path, out_onnx_file_path, image_shape, nms_iou_threshold, nms_top_k, nms_keep_top_k)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> os.path.exists(out_engine_file_path):</span><br><span class=\"line\">        build_engine(batch_size, out_onnx_file_path, out_engine_file_path, fp16_mode=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></div></figure>\n\n<h1 id=\"使用TensorRT引擎进行推理\">使用TensorRT引擎进行推理<a href=\"speed-up-pytorch-model-using-tensorrt#使用TensorRT引擎进行推理\"></a></h1><figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pycuda.driver <span class=\"keyword\">as</span> cuda</span><br><span class=\"line\"><span class=\"keyword\">import</span> tensorrt <span class=\"keyword\">as</span> trt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">TRT_LOGGER = trt.Logger()</span><br><span class=\"line\">trt.init_libnvinfer_plugins(TRT_LOGGER, <span class=\"string\">\"\"</span>)</span><br><span class=\"line\">explicit_batch = <span class=\"number\">1</span> &lt;&lt; (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">HostDeviceMem</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, host_mem, device_men)</span>:</span></span><br><span class=\"line\">        <span class=\"string\">\"\"\" Within this context, host_men meas the cpu memory, device_mem means the gpu memory\"\"\"</span></span><br><span class=\"line\">        self.host = host_mem</span><br><span class=\"line\">        self.device = device_men</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__str__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"string\">\"Host:\\n&#123;&#125;\\nDevice:&#123;&#125;\\n\"</span>.format(self.host, self.device)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__repr__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> self.__str__()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">allocate_buffers</span><span class=\"params\">(engine)</span>:</span></span><br><span class=\"line\">    inputs = []</span><br><span class=\"line\">    outputs = []</span><br><span class=\"line\">    bindings = []</span><br><span class=\"line\">    stream = cuda.Stream()</span><br><span class=\"line\">    <span class=\"keyword\">for</span> binding <span class=\"keyword\">in</span> engine:</span><br><span class=\"line\">        size = trt.volume(engine.get_binding_shape(binding))</span><br><span class=\"line\">        dtype = trt.nptype(engine.get_binding_dtype(binding))</span><br><span class=\"line\">        <span class=\"comment\"># Allocate host and device buffers</span></span><br><span class=\"line\">        host_mem = cuda.pagelocked_empty(size, dtype)</span><br><span class=\"line\">        device_mem = cuda.mem_alloc(host_mem.nbytes)</span><br><span class=\"line\">        <span class=\"comment\"># Append the device buffer to device bindings</span></span><br><span class=\"line\">        bindings.append(int(device_mem))</span><br><span class=\"line\">        <span class=\"keyword\">if</span> engine.binding_is_input(binding):</span><br><span class=\"line\">            inputs.append(HostDeviceMem(host_mem, device_mem))</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            outputs.append(HostDeviceMem(host_mem, device_mem))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> inputs, outputs, bindings, stream</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_engine</span><span class=\"params\">(engine_file_path)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(engine_file_path, <span class=\"string\">'rb'</span>) <span class=\"keyword\">as</span> f, trt.Runtime(TRT_LOGGER) <span class=\"keyword\">as</span> runtime:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> runtime.deserialize_cuda_engine(f.read())</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">do_inference</span><span class=\"params\">(context, bindings, inputs, outputs, stream, batch_size=<span class=\"number\">1</span>)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># Transfer data from CPU to the GPU.</span></span><br><span class=\"line\">    [cuda.memcpy_htod_async(input.device, input.host, stream) <span class=\"keyword\">for</span> input <span class=\"keyword\">in</span> inputs]</span><br><span class=\"line\">    <span class=\"comment\"># Run inference</span></span><br><span class=\"line\">    context.execute_async(batch_size=batch_size, bindings=bindings, stream_handle=stream.handle)</span><br><span class=\"line\">    <span class=\"comment\"># Transfer predictions back from the GPU.</span></span><br><span class=\"line\">    [cuda.memcpy_dtoh_async(output.host, output.device, stream) <span class=\"keyword\">for</span> output <span class=\"keyword\">in</span> outputs]</span><br><span class=\"line\">    <span class=\"comment\"># Synchronize the stream</span></span><br><span class=\"line\">    stream.synchronize()</span><br><span class=\"line\">    <span class=\"comment\"># Return only the host outputs.</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> [output.host <span class=\"keyword\">for</span> output <span class=\"keyword\">in</span> outputs]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Predictor</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, cfg)</span>:</span></span><br><span class=\"line\">        self.cfg = cfg.copy()</span><br><span class=\"line\">        self.input_size = cfg.MODEL.INPUT.SIZE</span><br><span class=\"line\"></span><br><span class=\"line\">        self.cuda_device = cuda.Device(cfg.MODEL.DEVICE)</span><br><span class=\"line\">        self.cuda_context = self.cuda_device.make_context()</span><br><span class=\"line\"></span><br><span class=\"line\">        self.engine = get_engine(cfg.MODEL.TENSORRT_WEIGHTS(cfg))</span><br><span class=\"line\">        self.context = self.engine.create_execution_context()</span><br><span class=\"line\"></span><br><span class=\"line\">        self.inputs, self.outputs, self.bindings, self.stream = allocate_buffers(self.engine)</span><br><span class=\"line\"></span><br><span class=\"line\">        self.max_batch_size = cfg.MODEL.BATCH_SIZE</span><br><span class=\"line\"></span><br><span class=\"line\">        self.thresholds = np.array([cfg.MODEL.PEOPLE_THRESHOLD, cfg.MODEL.CAR_THRESHOLD], dtype=np.float32)</span><br><span class=\"line\">        self.nms_threshold = cfg.MODEL.NMS_THRESHOLD</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__del__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        self.cuda_context.pop()</span><br><span class=\"line\">        <span class=\"keyword\">del</span> self.cuda_context</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__call__</span><span class=\"params\">(self, images, pixel_mean_std_list)</span>:</span></span><br><span class=\"line\">        self.cuda_context.push()</span><br><span class=\"line\">        batch_size = len(images)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> batch_size &gt; self.max_batch_size:</span><br><span class=\"line\">            <span class=\"keyword\">raise</span> Exception(<span class=\"string\">\"the max_batch_size is &#123;&#125;\"</span>.format(self.max_batch_size))</span><br><span class=\"line\">        </span><br><span class=\"line\">        images_width_height = np.array([[image.shape[<span class=\"number\">1</span>], image.shape[<span class=\"number\">0</span>]] <span class=\"keyword\">for</span> image <span class=\"keyword\">in</span> images], dtype=np.float32)</span><br><span class=\"line\">        pixel_mean_std = np.stack(pixel_mean_std_list, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        images, resize_params_list = zip(*[resize_padding(images[i], size=self.input_size, fill_pixel=pixel_mean_std[i, <span class=\"number\">0</span>]) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(images))])</span><br><span class=\"line\">        images = [np.expand_dims(image, <span class=\"number\">-1</span>) <span class=\"keyword\">if</span> len(image.shape) == <span class=\"number\">2</span> <span class=\"keyword\">else</span> image <span class=\"keyword\">for</span> image <span class=\"keyword\">in</span> images]</span><br><span class=\"line\"></span><br><span class=\"line\">        images = np.stack(images, axis=<span class=\"number\">0</span>).transpose(<span class=\"number\">0</span>, <span class=\"number\">3</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        self.inputs[<span class=\"number\">0</span>].host = images.reshape(<span class=\"number\">-1</span>).astype(<span class=\"string\">'float32'</span>)</span><br><span class=\"line\">        self.inputs[<span class=\"number\">1</span>].host = images_width_height</span><br><span class=\"line\">        self.inputs[<span class=\"number\">2</span>].host = pixel_mean_std</span><br><span class=\"line\">        self.inputs[<span class=\"number\">3</span>].host = self.thresholds</span><br><span class=\"line\"></span><br><span class=\"line\">        trt_outputs = do_inference(self.context, self.bindings, self.inputs, self.outputs, self.stream)</span><br><span class=\"line\"></span><br><span class=\"line\">        num_detections = trt_outputs[<span class=\"number\">0</span>][:batch_size]</span><br><span class=\"line\">        nmsed_boxes = trt_outputs[<span class=\"number\">3</span>].reshape(self.engine.max_batch_size, <span class=\"number\">-1</span>, <span class=\"number\">4</span>)[:batch_size]</span><br><span class=\"line\">        nmsed_scores = trt_outputs[<span class=\"number\">1</span>].reshape(self.engine.max_batch_size, <span class=\"number\">-1</span>)[:batch_size]</span><br><span class=\"line\">        nmsed_classes = trt_outputs[<span class=\"number\">2</span>].reshape(self.engine.max_batch_size, <span class=\"number\">-1</span>)[:batch_size]</span><br><span class=\"line\"></span><br><span class=\"line\">        prediction_list = [</span><br><span class=\"line\">            &#123;</span><br><span class=\"line\">                <span class=\"string\">'rois'</span>: nmsed_boxes[i, :num_detections[i]],</span><br><span class=\"line\">                <span class=\"string\">'class_ids'</span>: nmsed_classes[i, :num_detections[i]],</span><br><span class=\"line\">                <span class=\"string\">'scores'</span>: nmsed_scores[i, :num_detections[i]],</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">            <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(batch_size)</span><br><span class=\"line\">        ]</span><br><span class=\"line\"></span><br><span class=\"line\">        self.cuda_context.pop()</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> prediction_list</span><br></pre></td></tr></table></div></figure>\n\n<figure class=\"highlight\"><div><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> pycuda.driver <span class=\"keyword\">as</span> cuda</span><br><span class=\"line\"></span><br><span class=\"line\">cuda.init()</span><br><span class=\"line\"></span><br><span class=\"line\">cfg = ...</span><br><span class=\"line\">predictor = Predictor(cfg)</span><br><span class=\"line\"></span><br><span class=\"line\">images = ...</span><br><span class=\"line\">pixel_mean_std_list = ...</span><br><span class=\"line\">prediction_list = predictor(images, pixel_mean_std_list)</span><br></pre></td></tr></table></div></figure>\n\n<p>注意：</p>\n<ol>\n<li>推理的输出<code>trt_output</code>不一定会按照PyTorch输出时的顺序或修改后ONNX模型中的输出顺序，需要先确定根据输出输出大小、类型、数值确定。</li>\n<li>TensorRT引擎的输入和输出都是一维向量，输入前需要展开成一维向量，输出后将一维向量reshape成预定的大小。</li>\n<li>在进行推理前，对于每一个使用TensorRT的进程，需要先导入<code>pycuda.driver</code>，并使用<code>cuda.init()</code>进行初始化。</li>\n<li>使用TensorRT进行一次推理前需要先<code>cuda.context.push()</code>，并在推理完成后<code>cuda.context.pop()</code>。</li>\n</ol>\n","prev":{"title":"粒子群优化算法(Particle Swarm Optimization, PSO)","link":"particle-swarm-optimization"},"next":{"title":"强连通分量","link":"strongly-connected-component"},"plink":"https://yuxinzhao.net/speed-up-pytorch-model-using-tensorrt/","toc":[{"title":"PyTorch模型转换成TensorRT引擎的路径","id":"PyTorch模型转换成TensorRT引擎的路径","index":"1"},{"title":"环境准备","id":"环境准备","index":"2"},{"title":"PyTorch转换成ONNX","id":"PyTorch转换成ONNX","index":"3","children":[{"title":"准备待转换的PyTorch模型","id":"准备待转换的PyTorch模型","index":"3.1"},{"title":"转换PyTorch到ONNX","id":"转换PyTorch到ONNX","index":"3.2"},{"title":"简化静态图","id":"简化静态图","index":"3.3"}]},{"title":"ONNX转换成TensorRT","id":"ONNX转换成TensorRT","index":"4","children":[{"title":"添加非极大值抑制插件","id":"添加非极大值抑制插件","index":"4.1"},{"title":"将ONNX从动态形状转换成固定形状","id":"将ONNX从动态形状转换成固定形状","index":"4.2"},{"title":"转换ONNX到TensorRT","id":"转换ONNX到TensorRT","index":"4.3"}]},{"title":"使用TensorRT引擎进行推理","id":"使用TensorRT引擎进行推理","index":"5"}],"reward":true,"copyright":{"author":"Yuxin Zhao","link":"<a href=\"https://yuxinzhao.net/speed-up-pytorch-model-using-tensorrt/\" title=\"使用TensorRT加速PyTorch模型\">https://yuxinzhao.net/speed-up-pytorch-model-using-tensorrt/</a>","license":"Attribution-NonCommercial-NoDerivatives 4.0 International (<a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\" rel=\"external nofollow noopener\" target=\"_blank\">CC BY-NC-ND 4.0</a>)"}}