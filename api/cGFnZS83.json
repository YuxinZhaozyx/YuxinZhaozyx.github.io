{"per_page":10,"total":7,"current":7,"data":[{"title":"What is IoU","date":"2019-07-15T20:20:32.000Z","excerpt":"<p>在目标检测任务中常常用IoU来计算预测窗口与真实窗口的交叠率。本文介绍IoU的概念。</p>","link":"what-is-IoU","tags":["IoU","metric"],"categories":["machine-learning"]},{"title":"What is RoI pooling","date":"2019-07-15T11:52:13.000Z","excerpt":"<p><a href=\"/what-is-RoI/\">上文</a>讲了什么是RoI(Region of Interest, 感兴趣区域)，本文讲述RoI Pooling的概念。</p>","link":"what-is-RoI-pooling","tags":["RoI","metric","pooling"],"categories":["machine-learning"]},{"title":"What is RoI","date":"2019-07-15T11:07:26.000Z","excerpt":"","link":"what-is-RoI","tags":["RoI","metric"],"categories":["machine-learning"]},{"title":"[论文笔记] Faster R-CNN: Towards Real-Time Object Detection With Region Proposal Networks","date":"2019-07-14T13:40:12.000Z","thumbnail":"/static/image/faster-r-cnn.png","excerpt":"<p>Faster R-CNN在Fast R-CNN的基础上做改进，提出用RPN（Region Proposal Network, 一种全卷积神经网络）代替Selective Search，降低检测耗时。Faster R-CNN由RPN和Fast R-CNN构成，RPN和Fast R-CNN共享卷积计算得到的特征图，以此降低计算量，使得Faster R-CNN可以在单GPU上以5fps的速度运行，且精度达到SOTA。</p>","link":"faster-r-cnn","tags":["object-detection"],"categories":["paper-note"]},{"title":"git merge命令提示Already up to date","date":"2019-07-09T14:45:33.000Z","excerpt":"<p>本文描述 <code>git merge &lt;branch&gt;</code> 提示 Already up to date 的错误原因及解决方法。</p>","link":"git-merge-already-up-to-date","tags":["error","git"],"categories":["tools"]},{"title":"[论文笔记] Two-Stream Convolutional Networks for Action Recognition in Videos","date":"2019-02-24T18:56:15.000Z","excerpt":"<p>The <a href=\"https://arxiv.org/pdf/1406.2199.pdf\" title=\"Two-Stream Convolutional Networks for Action Recognition in Videos\" target=\"_blank\" rel=\"noopener\">paper</a> is by Karen Simonyan, Andrew Zisserman.</p>\n<p><strong>Publication date :</strong> 12 Nov 2014</p>","link":"two-stream-convolutional-network","tags":["action-recognition","optical-flow","two-stream"],"categories":["paper-note"]},{"title":"[论文笔记] Long-term Recurrent Convolutional Networks for Visual Recognition and Description","date":"2019-02-22T20:27:20.000Z","excerpt":"<p>The <a href=\"https://arxiv.org/pdf/1411.4389.pdf\" title=\"Long-term Recurernt Convolutional Networks for Visual Recognition and Description\" target=\"_blank\" rel=\"noopener\">paper</a> is by Jeff Donahue, Lisa Anne Hendricks, Marcus Rohrbach, Subhashini Venugopalan, Sergio Guadarrama, Kate Saenko, Trevor Darrell.</p>\n<p><strong>Publication date :</strong> 31 May 2016</p>\n<p><strong>Code and pre-trained model</strong> are availabled at <a href=\"https://people.eecs.berkeley.edu/~lisa_anne/LRCN_video\" target=\"_blank\" rel=\"noopener\">here</a>.</p>","link":"lrcn","tags":["LRCN","activity-recognition","image-captioning","video-description"],"categories":["paper-note"]},{"title":"[论文笔记] Learning Spatiotemporal Features with 3D Convolutional Networks","date":"2019-02-18T15:36:20.000Z","excerpt":"<p>The <a href=\"https://arxiv.org/pdf/1412.0767.pdf\" title=\"Learning Spatiotemporal Features with 3D Convolutional Networks\" target=\"_blank\" rel=\"noopener\">paper</a> is by Du Tran, Lubomir Bourdev, Rob Fergus, Lorenzo Torresani, Manohar Paluri.</p>\n<p><strong>Publication date :</strong> 7 Oct 2015</p>\n<p><strong>C3D source code and pre-trained model</strong> are available at <a href=\"http://vlg.cs.dartmouth.edu/c3d\" target=\"_blank\" rel=\"noopener\">here</a>.</p>","link":"c3d","tags":["C3D","action-recognition","action-similarity-labeling","object-recognition","scene-recognition"],"categories":["paper-note"]}]}